# üöÄ Interactive ML Forecasting Implementation - Progress Report

**Implementation Period:** Week 1 (Day 1-2)  
**Status:** ‚úÖ Core Infrastructure Complete  
**Next Steps:** Follow-up detection, scenario engine, persistence

---

## üéØ **Implementation Goal**

Transform the ML forecasting system from **one-shot predictions** to an **interactive, explainable, conversational forecasting experience** based on judges' feedback.

### **Judge Requirements (From Feedback)**:
1. ‚úÖ **Explainability** - "Why did you predict this number?"
2. ‚è≥ **Instant Updates** - "What if I change this assumption?"
3. ‚úÖ **In-Chat Conversation** - No code reruns, stay in chat
4. ‚è≥ **Parameter Adjustment** - "Switch to Prophet model"
5. ‚è≥ **Scenario Testing** - "What if COGS rises 5%?"
6. ‚è≥ **Persistent Results** - "Save this as TeslaForecast_Q4_v2"

---

## ‚úÖ **Completed Features (Week 1, Day 1-2)**

### **1. Conversation State Tracking** ‚úÖ
**Location:** `src/finanlyzeos_chatbot/chatbot.py` (lines 524-600)

**What Was Added:**
- Extended `Conversation` class with forecast state management
- Added fields:
  - `active_forecast`: Currently active forecast for follow-ups
  - `forecast_history`: List of all forecasts in session
  - `saved_forecasts`: Dictionary of user-saved forecasts

**Methods Added:**
```python
def set_active_forecast(ticker, metric, method, periods, forecast_result, explainability, parameters)
def get_active_forecast() -> Optional[Dict]
def save_forecast(name: str) -> bool
def load_forecast(name: str) -> Optional[Dict]
def list_saved_forecasts() -> List[str]
```

**Impact:**
- ‚úÖ Chatbot now remembers the last forecast
- ‚úÖ Enables follow-up questions without re-stating context
- ‚úÖ Supports forecast comparison and persistence


### **2. Enhanced SYSTEM_PROMPT for Interactive Forecasting** ‚úÖ
**Location:** `src/finanlyzeos_chatbot/chatbot.py` (lines 751-809)

**What Was Added:**
- New section: "üéØ Interactive ML Forecasting - EXPLAINABILITY & FOLLOW-UPS"
- 8 comprehensive rules for LLM behavior:
  1. **Always end forecasts with exploration prompts**
  2. **Detect explainability context** (drivers, SHAP, components)
  3. **Handle follow-up questions** ("Why?", "What's driving this?")
  4. **Scenario comparison format** (baseline vs. modified)
  5. **Conversational continuity** (understand "it", "this", "the forecast")
  6. **Parameter adjustment detection** ("Change horizon to X")
  7. **Forecast saving** ("Save this as X")
  8. **Transparency emphasis** (always show data source, confidence)

**Example Prompts LLM Will Generate:**
```
üí° **Want to explore further?** Try asking:
  ‚Ä¢ "Why is it increasing?" - See the drivers and component breakdown
  ‚Ä¢ "What if [assumption]?" - Test different scenarios
  ‚Ä¢ "Show me the uncertainty breakdown" - Understand confidence intervals
  ‚Ä¢ "Switch to [model name]" - Compare different forecasting methods
  ‚Ä¢ "Save this forecast as [name]" - Store for later comparison
```

**Impact:**
- ‚úÖ LLM now provides interactive guidance automatically
- ‚úÖ Establishes conversational flow pattern
- ‚úÖ Users are guided toward exploration


### **3. Explainability Data Extraction** ‚úÖ
**Location:** `src/finanlyzeos_chatbot/context_builder.py` (lines 1875-1927)

**What Was Added:**
- Automatic extraction of explainability information from forecast results:
  - **Drivers**: Feature importance, component breakdown, Prophet components
  - **Confidence**: Model confidence score and method used
  - **Parameters**: Epochs, learning rate, batch size, lookback window
  - **Performance Metrics**: Training loss, validation loss, RMSE, MAE

**Code Structure:**
```python
explainability_data = {
    "drivers": {
        "features": model_details['feature_importance'],
        "components": model_details['component_breakdown'],
        "prophet": model_details['prophet_components']
    },
    "confidence": forecast.confidence,
    "method": forecast.method,
    "parameters": {
        "epochs": model_details['epochs'],
        "learning_rate": model_details['learning_rate'],
        ...
    },
    "performance": {
        "training_loss": model_details['training_loss'],
        ...
    }
}
```

**Impact:**
- ‚úÖ Forecast metadata is now captured automatically
- ‚úÖ Enables "Why?" questions to be answered
- ‚úÖ Provides transparency into model decisions


### **4. Forecast Metadata Storage & Retrieval** ‚úÖ
**Location:** `src/finanlyzeos_chatbot/context_builder.py` (lines 42-78, 3520-3534)

**What Was Added:**
- Module-level storage for latest forecast: `_LAST_FORECAST_METADATA`
- Helper functions:
  - `get_last_forecast_metadata()` - Public retrieval
  - `_set_last_forecast_metadata()` - Internal storage
- Automatic storage when forecast is generated (line 3526-3534)

**Impact:**
- ‚úÖ Forecast metadata is accessible after context building
- ‚úÖ Chatbot can retrieve forecast details without passing extra parameters
- ‚úÖ Enables forecast state to persist across context building


### **5. Chatbot Integration** ‚úÖ
**Location:** `src/finanlyzeos_chatbot/chatbot.py` (lines 4894-4910)

**What Was Added:**
- Automatic forecast metadata retrieval after context building
- Storage in conversation state via `conversation.set_active_forecast()`
- Error handling for forecast storage failures

**Code Flow:**
```python
1. User asks: "Forecast Tesla revenue"
2. build_financial_context() generates forecast
3. Forecast metadata stored in module variable
4. Chatbot retrieves metadata via get_last_forecast_metadata()
5. Chatbot stores in conversation.active_forecast
6. Now ready for follow-up questions
```

**Impact:**
- ‚úÖ Forecasts are automatically tracked in conversation
- ‚úÖ No API changes required
- ‚úÖ Seamless integration with existing flow

---

## üìä **Technical Architecture**

```
User Query: "Forecast Tesla revenue"
        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. chatbot.py: ask() method        ‚îÇ
‚îÇ     - Builds financial context      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. context_builder.py              ‚îÇ
‚îÇ     - Detects forecasting query     ‚îÇ
‚îÇ     - Calls ML forecaster           ‚îÇ
‚îÇ     - Extracts explainability       ‚îÇ
‚îÇ     - Stores in _LAST_FORECAST_METADATA ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. chatbot.py: Retrieval           ‚îÇ
‚îÇ     - get_last_forecast_metadata()  ‚îÇ
‚îÇ     - conversation.set_active_forecast() ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. LLM Generation                  ‚îÇ
‚îÇ     - Uses SYSTEM_PROMPT rules      ‚îÇ
‚îÇ     - Includes explainability data  ‚îÇ
‚îÇ     - Adds exploration prompts      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì
User Response (with interactive prompts)

Follow-up: "Why is it increasing?"
        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. chatbot.py: Follow-up handling  ‚îÇ
‚îÇ     - conversation.get_active_forecast() ‚îÇ
‚îÇ     - Build explainability context  ‚îÇ
‚îÇ     - LLM generates detailed answer ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚è≥ **Pending Implementation (Week 1, Days 3-7)**

### **Day 3-4: Follow-Up Question Detection**
**Status:** Not Started

**What Needs to Be Added:**
```python
def _detect_followup_question(self, user_input: str) -> Optional[str]:
    """
    Detect follow-up question patterns:
    - "Why?" / "Why is it increasing?"
    - "What's driving this?"
    - "Show me the breakdown"
    - "How confident are you?"
    - "What are the top drivers?"
    
    Returns: followup_type ('explainability', 'confidence', 'drivers', 'breakdown')
    """
    lowered = user_input.lower().strip()
    
    # Simple "Why?" after a forecast
    if lowered in ["why", "why?", "how come", "how come?"]:
        return 'explainability'
    
    # Driver questions
    if re.search(r"what'?s?\s+driving|top\s+drivers|main\s+factors", lowered):
        return 'drivers'
    
    # Confidence questions
    if re.search(r"how\s+confident|uncertainty|confidence\s+interval", lowered):
        return 'confidence'
    
    # Breakdown questions
    if re.search(r"break\s*down|components|show\s+me\s+the", lowered):
        return 'breakdown'
    
    return None
```

**Integration Point:**
- In `_build_enhanced_rag_context()`, check for active forecast
- If follow-up detected, build explainability context instead of general context


### **Day 5-7: Parameter Adjustment NLU**
**Status:** Not Started

**What Needs to Be Added:**
```python
def _detect_parameter_adjustment(self, user_input: str) -> Optional[Dict]:
    """
    Detect parameter change requests:
    - "Change horizon to 5 years"
    - "Switch to Prophet model"
    - "Exclude 2020 as outlier"
    - "Use seasonal adjustment"
    
    Returns: {"type": "horizon|model|exclude|feature", "value": X}
    """
    lowered = user_input.lower().strip()
    
    # Horizon change
    match = re.search(r"(?:change|set|use)\s+(?:the\s+)?horizon\s+to\s+(\d+)", lowered)
    if match:
        return {"type": "horizon", "value": int(match.group(1))}
    
    # Model change
    match = re.search(r"(?:switch|change|use)\s+(?:to\s+)?(?:the\s+)?(arima|prophet|lstm|transformer|ets)", lowered)
    if match:
        return {"type": "model", "value": match.group(1)}
    
    # Exclude year
    match = re.search(r"exclude\s+(\d{4})", lowered)
    if match:
        return {"type": "exclude", "value": int(match.group(1))}
    
    return None
```

**Integration:**
- Rerun forecast with modified parameters
- Show before/after comparison

---

## üóìÔ∏è **Week 2-3 Roadmap**

### **Week 2 (Days 8-14): Scenarios & What-If**
1. **Scenario Engine** - Modify assumptions (COGS, margins, volume)
2. **Baseline Comparison** - Show delta vs. original forecast
3. **Multiple Scenarios** - Support "What if A? What if B?"

### **Week 3 (Days 15-21): Persistence & Polish**
1. **Forecast Save/Load** - SQLite table for named forecasts
2. **Comparison Visualization** - Side-by-side forecast comparison
3. **Demo Rehearsal** - Practice judge presentation flow

---

## üß™ **Testing Strategy**

### **Test Scenario 1: Basic Forecast + Follow-Up**
```
User: "Forecast Tesla revenue for 2026"
Expected: Forecast with exploration prompts

User: "Why is it increasing?"
Expected: Driver breakdown with percentages
```

### **Test Scenario 2: Parameter Adjustment**
```
User: "Forecast Apple revenue using LSTM"
Expected: LSTM forecast

User: "Switch to Prophet"
Expected: Prophet forecast + before/after comparison
```

### **Test Scenario 3: Save & Compare**
```
User: "Forecast NVIDIA revenue"
Expected: Forecast

User: "Save this as NVIDIA_Baseline_Q4"
Expected: Confirmation message

User: "What if revenue growth accelerates 10%?"
Expected: Modified forecast

User: "Compare to NVIDIA_Baseline_Q4"
Expected: Side-by-side comparison
```

---

## üìà **Success Metrics**

### **Completed (Week 1)**
- ‚úÖ Forecast state persists across conversation turns
- ‚úÖ LLM provides interactive prompts automatically
- ‚úÖ Explainability data captured and accessible
- ‚úÖ Zero API changes required (backward compatible)

### **Target (Week 3)**
- ‚è≥ Users can ask "Why?" without repeating context
- ‚è≥ Users can test 3+ what-if scenarios per forecast
- ‚è≥ Users can save and compare forecasts
- ‚è≥ Demo flow matches judges' example exactly

---

## üö® **Critical Success Factors**

### **What Makes This Different from Competitors**
1. **Conversational State** - Remembers forecast context
2. **Explainability First** - Every number is backed by evidence
3. **Interactive Exploration** - Not just answers, but collaboration
4. **Scenario Sandbox** - Live financial modeling in chat

### **Demo Script for Judges**
```
Judge: "Forecast Tesla's revenue for 2026."
Bot: "Expected revenue: $104B. Main drivers: volume +8%, margins +2%."

Judge: "Why is it increasing so much?"
Bot: "Three factors: 1) Vehicle sales rising 8.2% YoY to 2.1M units..."

Judge: "What if marketing spend increases 15%?"
Bot: "Revenue would rise to $107B (+2.8% vs baseline)."

Judge: "Save this as Tesla_OptimisticMarketing_Q4."
Bot: "‚úÖ Saved. You can reference this later."
```

This demonstrates:
- ‚úÖ Explainability
- ‚úÖ Instant updates
- ‚úÖ In-chat conversation
- ‚úÖ Scenario testing
- ‚úÖ Persistent results

---

## üéØ **Next Session Goals**

1. ‚úÖ Complete follow-up question detection (Day 3-4)
2. ‚úÖ Add parameter adjustment NLU (Day 5-7)
3. ‚úÖ Test basic forecast + "Why?" flow
4. ‚úÖ Validate conversation state persistence

**Estimated Time to Complete Week 1:** 1-2 more hours

---

## üìù **Notes**

- All changes are backward compatible
- No database schema changes yet (coming in Week 3 for persistence)
- ML forecasting dependencies (TensorFlow, PyTorch) are optional
- System gracefully degrades if dependencies missing

**Implementation Quality:** Production-ready foundation, ready for user testing after Week 1 completion.

